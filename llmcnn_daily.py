# -*- coding: utf-8 -*-
"""LLMCNN-daily.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PdmMVq-NtbuvpvYWAlfu_Kv5rW89zNrR

1. Mount to Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""2. Install Libraries"""

!pip install -q transformers datasets rouge-score accelerate
!pip install -q sentencepiece
import pandas as pd
from transformers import T5Tokenizer
from datasets import Dataset

"""3. Load the CSV Files that Uploaded on Google Drive"""

train_df = pd.read_csv('/content/drive/MyDrive/cnn_dailymail/train.csv')
val_df   = pd.read_csv('/content/drive/MyDrive/cnn_dailymail/validation.csv')
test_df  = pd.read_csv('/content/drive/MyDrive/cnn_dailymail/test.csv')

print(train_df.columns)
train_df.head()

# âœ… Sample smaller datasets for faster training
train_df = train_df.sample(5000, random_state=42).reset_index(drop=True)
val_df = val_df.sample(1000, random_state=42).reset_index(drop=True)
test_df = test_df.sample(1000, random_state=42).reset_index(drop=True)

"""4. Data Preprocessing"""

train_df = train_df[['article', 'highlights']].dropna()
val_df = val_df[['article', 'highlights']].dropna()
test_df = test_df[['article', 'highlights']].dropna()

# Rename for model compatibility
train_df.columns = ['text', 'summary']
val_df.columns = ['text', 'summary']
test_df.columns = ['text', 'summary']

"""5. Hugging Face Tokenizer"""

model_name = "t5-small"
tokenizer = T5Tokenizer.from_pretrained(model_name)

def tokenize_function(batch):
    input_encodings = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=512)
    target_encodings = tokenizer(batch['summary'], truncation=True, padding='max_length', max_length=150)
    input_encodings['labels'] = target_encodings['input_ids']
    return input_encodings

"""6. Convert DataFrames to HuggingFace Format"""

train_dataset = Dataset.from_pandas(train_df)
val_dataset = Dataset.from_pandas(val_df)
test_dataset = Dataset.from_pandas(test_df)

train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)
test_dataset = test_dataset.map(tokenize_function, batched=True)

# Set format for PyTorch
train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])
test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])

"""7. Save the Preprocessed Dataset in Disk"""

train_dataset.save_to_disk("/content/train_dataset")
val_dataset.save_to_disk("/content/val_dataset")
test_dataset.save_to_disk("/content/test_dataset")

"""8. Fix NumPy Compatibility Issue with Hugging Face Datasets"""

!pip uninstall -y thinc spacy
!pip install -q --force-reinstall numpy==1.26.4
import os
os.kill(os.getpid(), 9)

"""9. Read the Saved Dataset"""

from datasets import load_from_disk

train_dataset = load_from_disk("/content/train_dataset")
val_dataset = load_from_disk("/content/val_dataset")
test_dataset = load_from_disk("/content/test_dataset")

"""10. Import Libraries"""

from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments
from datasets import load_metric
import numpy as np

"""11. Load T5-small Model and Train"""

model_name = "t5-small"

model = T5ForConditionalGeneration.from_pretrained(model_name)

training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=1,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=10,
    push_to_hub=False,
    load_best_model_at_end=True,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
)

trainer.train()

"""12. Evaluate the Model with ROUGE Score"""

!pip install evaluate

from evaluate import load
rouge = load("rouge")
eval_results = trainer.evaluate()

print("Evaluation Results (ROUGE):")
for key, value in eval_results.items():
    print(f"{key}: {value:.2f}")

print(test_dataset.column_names)

from transformers import T5Tokenizer

# tokenizer
tokenizer = T5Tokenizer.from_pretrained("t5-small")

for i in range(3):
    input_ids = test_dataset[i]["input_ids"]
    input_text = tokenizer.decode(input_ids, skip_special_tokens=True)
    summary = summarize(input_text)
    print(f"\nOriginal Text:\n{input_text[:500]}...\n")
    print(f"Generated Summary:\n{summary}\n")

"""13. Test on New Data"""

preds = []
refs = []

for example in test_dataset:
    # Decode input_ids to text
    input_text = tokenizer.decode(example["input_ids"], skip_special_tokens=True)
    label_ids = example["labels"]
    label_ids = [token if token != -100 else tokenizer.pad_token_id for token in label_ids]
    reference = tokenizer.decode(label_ids, skip_special_tokens=True)

    generated = summarize(input_text)

    preds.append(generated)
    refs.append(reference)

# Compute ROUGE
test_rouge = rouge.compute(predictions=preds, references=refs, use_stemmer=True)

print("Test ROUGE Scores:")
for key, value in test_rouge.items():
    print(f"{key}: {value * 100:.2f}")

"""14. Save Model and Tokenizer"""

#model.save_pretrained("t5_summarizer_model")
#tokenizer.save_pretrained("t5_summarizer_model")